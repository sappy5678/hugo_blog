<!doctype html><html lang=zh-tw><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=theme-color content="#494f5c"><meta name=msapplication-TileColor content="#494f5c"><meta itemprop=name content="社群網路筆記 賽局理論"><meta itemprop=description content="賽局理論最大的特色在於，他有許多決策者 名詞 Player Strategies Payoff Payoff Matrix 目前先考慮 one shot game player 同時下決策，且 player 之間的決策過程是獨立的 幾個假設 player 只關注如何最大化自身利"><meta itemprop=datePublished content="2020-04-11T18:13:30+00:00"><meta itemprop=dateModified content="2020-04-11T18:13:30+00:00"><meta itemprop=wordCount content="803"><meta itemprop=keywords content="課程,社群網路,"><meta property="og:title" content="社群網路筆記 賽局理論"><meta property="og:description" content="賽局理論最大的特色在於，他有許多決策者 名詞 Player Strategies Payoff Payoff Matrix 目前先考慮 one shot game player 同時下決策，且 player 之間的決策過程是獨立的 幾個假設 player 只關注如何最大化自身利"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.sappy.tw/posts/%E5%A4%A7%E5%AD%B8%E5%AD%B8%E7%BF%92/%E7%A4%BE%E7%BE%A4%E7%B6%B2%E8%B7%AF/%E7%A4%BE%E7%BE%A4%E7%B6%B2%E8%B7%AF_%E8%B3%BD%E5%B1%80/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-04-11T18:13:30+00:00"><meta property="article:modified_time" content="2020-04-11T18:13:30+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="社群網路筆記 賽局理論"><meta name=twitter:description content="賽局理論最大的特色在於，他有許多決策者 名詞 Player Strategies Payoff Payoff Matrix 目前先考慮 one shot game player 同時下決策，且 player 之間的決策過程是獨立的 幾個假設 player 只關注如何最大化自身利"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color><link rel="shortcut icon" href=/favicon.ico><title>社群網路筆記 賽局理論</title><link rel=stylesheet href=https://blog.sappy.tw/css/style.min.037b6ee8f8c1baab6a3d0a9da11c3ff18a7552471f16c59fd98538d5ce99208b.css integrity="sha256-A3tu6PjBuqtqPQqdoRw/8Yp1UkcfFsWf2YU41c6ZIIs=" crossorigin=anonymous></head><body id=page><header id=site-header class="animated slideInUp"><div class="hdr-wrapper section-inner"><div class=hdr-left><div class=site-branding><a href=https://blog.sappy.tw>sappy blog</a></div><nav class="site-nav hide-in-mobile"><a href=https://blog.sappy.tw/posts/>Posts</a>
<a href=https://blog.sappy.tw/about-hugo/>About</a></nav></div><div class="hdr-right hdr-icons"><span class="hdr-social hide-in-mobile"><a href=https://github.com/sappy5678 target=_blank rel="noopener me" title=Github><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span><button id=menu-btn class=hdr-btn title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button></div></div></header><div id=mobile-menu class="animated fast"><ul><li><a href=https://blog.sappy.tw/posts/>Posts</a></li><li><a href=https://blog.sappy.tw/about-hugo/>About</a></li></ul></div><main class="site-main section-inner animated fadeIn faster"><article class=thin><header class=post-header><div class=post-meta><span>Apr 11, 2020</span></div><h1>社群網路筆記 賽局理論</h1></header><div class=content><p>賽局理論最大的特色在於，他有許多決策者</p><h1 id=名詞>名詞<a href=#名詞 class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><ol><li>Player</li><li>Strategies</li><li>Payoff</li><li>Payoff Matrix</li></ol><p>目前先考慮 one shot game
player 同時下決策，且 player 之間的決策過程是獨立的</p><p>幾個假設</p><ol><li>player 只關注如何最大化自身利益 - rationality</li><li>player 不關心他人或集體的利益</li><li>player 能完整知道整個 game 的訊息(也有不知道所有訊息的 game)</li></ol><p>TODO 例子</p><h1 id=best-responses--dominant-strategies>Best Responses & Dominant Strategies<a href=#best-responses--dominant-strategies class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>當其他人選 T 時， S 是最好的選擇</p><h1 id=strictly-dominant-strategy>Strictly Dominant Strategy<a href=#strictly-dominant-strategy class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>無論其他怎麼選，都是最優的選項
最優的選項 - 大於其他所有選項</p><p>TODO 例子 - 囚犯困境 - 都有Strictly Dominant Strategy</p><p>TODO 例子 - 只有一方有 Strictly Dominant Strategy</p><h1 id=nash-equilibrium>Nash Equilibrium<a href=#nash-equilibrium class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>解決都不存在 Strictly Dominant Strategy 的狀況</p><p>在這組決策下，沒有任何一方能夠通過改變自己的決策獲取更多利益，使其他人沒有動機改變決策</p><p>TODO 三人例子</p><p>找 Nash 的方法</p><ol><li>暴力搜尋所有組合</li><li>找每一個人的所有 best responses，並交集所有人的 best responses - 比較好的方法</li></ol><h2 id=coordination-game---多個-nash-equilibrium>coordination game - 多個 Nash Equilibrium<a href=#coordination-game---多個-nash-equilibrium class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h2><p>TODO 變種 + 特例
<a href=https://en.wikipedia.org/wiki/Coordination_game>https://en.wikipedia.org/wiki/Coordination_game</a></p><ol><li>Coordination game</li><li>Unbalanced coordination game</li><li>Battle of the sexes</li><li>Mis-coordination games - 如果沒協調好的話，追求最大利益的反而懲罰越大</li></ol><h1 id=mixed-strategies>Mixed strategies<a href=#mixed-strategies class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>引入機率，讓對手更難預測自身的行為 -> 讓對手選哪個選項 payoff 都相同(indifference)
透過引入機率，解決沒有 Nash Equilibrium 的問題
之前的決策沒有機率，所以撐過 pure strategies</p><p>TODO 例子 - pennies game</p><p>zero sum 零和遊戲 - payoff 加總唯一常數</p><p>TODO 例子</p><p>!!! 在有限的 player 跟 有限的策略時，一定有 mixed strategiy equilibrium</p><p>TODO 有兩個 mixed Nash Equilibrium 的例子</p><p>找Nash 的方法</p><ol><li>先用 pure strategies 方式去找</li><li>找不到再用 mixed</li></ol><h1 id=pareto-optimality>Pareto Optimality<a href=#pareto-optimality class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>考慮整體的利益，不一定能達到整體最好，但能達到局部最好
當存在一種組合，使每個人的 payoff 都比現在的組合好的時候，現在的組合即不是 pareto optimality</p><p>TODO 例子</p><h1 id=social-optimal>Social Optimal<a href=#social-optimal class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>把每個人的 payoff 加總，最大的那個組合</p><p>TODO 證明 如果是 social optimal 則一定是 pareto optimal</p><h1 id=dominated-strategies>Dominated Strategies<a href=#dominated-strategies class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>注意 Dominated strategies != Dominant Strategies
即有選擇全面的比現有選擇還要好，主要用來降低 Game 的分析複雜度</p><p>TODO 例子</p><p>策略組合 = outcome = choice of strategy = joint strategy = strategy profile = strategy combination = action profile</p><h2 id=證明>證明<a href=#證明 class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h2><ol><li>有沒有可能把 Nash Equilibrium 刪了?</li><li>有沒有可能剩下的 Nash Equilibrium 原本不是 Nash Equilibrium</li></ol><h1 id=weekly-dominate-strategies>Weekly Dominate Strategies<a href=#weekly-dominate-strategies class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>即 >=</p><h1 id=dynamic-game>Dynamic Game<a href=#dynamic-game class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>不同時執行
之前的 game 又叫做 normal form = strategic game = matrix game
現在 Game 叫做 Dynamic game = extensive form</p><p>解法</p><ol><li>動態規劃解，由下往上 - 這比較好 - Backward induction</li><li>轉成 matrix 解 - 有些解不存在，會有多的 Nash Equilibrium</li></ol><h1 id=subgame-perfect-equilibrium>Subgame perfect equilibrium<a href=#subgame-perfect-equilibrium class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>在所有 subgame 中都是最好的
Subgame perfect equilibrium 是 Nash
但 Nash 不一定是 Subgame perfect equilibrium</p><p>QQAQQQQQQQQQQ</p></div><hr class=post-end><footer class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=tag><a href=https://blog.sappy.tw/tags/%E8%AA%B2%E7%A8%8B>課程</a></span><span class=tag><a href=https://blog.sappy.tw/tags/%E7%A4%BE%E7%BE%A4%E7%B6%B2%E8%B7%AF>社群網路</a></span></p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg></p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>2020-04-11 18:13 +0000</p></footer></article><div class="post-nav thin"><a class=next-post href=https://blog.sappy.tw/posts/%E5%A4%A7%E5%AD%B8%E5%AD%B8%E7%BF%92/%E7%A4%BE%E7%BE%A4%E7%B6%B2%E8%B7%AF/%E7%A4%BE%E7%BE%A4%E7%B6%B2%E8%B7%AF_auctions/><span class=post-nav-label><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"/><polyline points="12 19 5 12 12 5"/></svg>&nbsp;</span><br><span>社群網路筆記 拍賣</span></a>
<a class=prev-post href=https://blog.sappy.tw/posts/%E5%A4%A7%E5%AD%B8%E5%AD%B8%E7%BF%92/%E7%A4%BE%E7%BE%A4%E7%B6%B2%E8%B7%AF/%E7%A4%BE%E7%BE%A4%E7%B6%B2%E8%B7%AF%E7%AD%86%E8%A8%98_1/><span class=post-nav-label>&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"/><polyline points="12 5 19 12 12 19"/></svg></span><br><span>社群網路筆記 1</span></a></div><div id=comments class=thin><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//sappy-blog.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></main><footer id=site-footer class="section-inner thin animated fadeIn faster"><p>&copy; 2022 <a href=https://blog.sappy.tw>sappy</a> &#183; <a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank rel=noopener>CC BY-NC 4.0</a></p><p>Made with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> &#183; Theme <a href=https://github.com/Track3/hermit target=_blank rel=noopener>Hermit</a> &#183; <a href=https://blog.sappy.tw/posts/index.xml target=_blank title=rss><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></p></footer><script src=https://blog.sappy.tw/js/bundle.min.580988ed2982bcbb74a1773c7abea97b43e4c43b9324e10cda0813ec6ec4bb67.js integrity="sha256-WAmI7SmCvLt0oXc8er6pe0PkxDuTJOEM2ggT7G7Eu2c=" crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-153138277-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>